{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWnXDXA_ostJ"
   },
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/pr-Mais/arabic-reverse-dictionary/blob/main/code/mt5_training_shared_task.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bayx6hJd62NA"
   },
   "source": [
    "# Fine-tuning MT5 for Reverse Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R0wp6owho42L",
    "outputId": "3a5e7691-c274-4389-ea0d-9e85ab169aed"
   },
   "outputs": [],
   "source": [
    "# This script is used to mount the google drive to the colab environment.\n",
    "import sys\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqUvEpNQ62NC"
   },
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We require the following libraries for the modeling process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "82oT0-Ljg1bj",
    "outputId": "055719cd-319f-4401-cf02-29fa01445cc7"
   },
   "outputs": [],
   "source": [
    "!pip3 install -q -U datasets==2.18.0\n",
    "!pip3 install -q -U transformers==4.39.2\n",
    "!pip3 install -q -U evaluate==0.4.1\n",
    "!pip3 install -q -U scikit-learn==1.4.1.post1\n",
    "!pip3 install -q -U torch==2.2.1\n",
    "!pip3 install -q -U tokenizers==0.15.2\n",
    "!pip3 install -q -U tqdm==4.66.2\n",
    "!pip3 install -q -U pandas==2.2.1\n",
    "!pip3 install -q -U numpy==1.26.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we import all required libraries and modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "20Q60mSlg2h_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from typing import Literal\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AdamW,\n",
    "    set_seed,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "from transformers.modeling_outputs import Seq2SeqLMOutput\n",
    "\n",
    "# For reproducibility\n",
    "set_seed(123)\n",
    "checkpoint = \"UBC-NLP/AraT5v2-base-1024\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "TargetEmbeddingType = Literal[\"electra\", \"bertseg\", \"bertmsa\"]\n",
    "\n",
    "# The max length of the embeddings, this should\n",
    "# match the length of the target embeddings length.\n",
    "max_length = {\n",
    "    \"electra\": 256,\n",
    "    \"bertseg\": 768,\n",
    "    \"bertmsa\": 768,\n",
    "}\n",
    "\n",
    "# Which target embedding to use as the target for the model?\n",
    "target_embedding: TargetEmbeddingType = \"bertseg\"\n",
    "max_length = max_length[target_embedding]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zUANoOaostL"
   },
   "source": [
    "### Loading and preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_path = \"../data/shared-task/train_with_examples.json\"\n",
    "val_ds_path = \"../data/shared-task/dev.json\"\n",
    "test_ds_path = \"../data/shared-task/test.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cHdKsHzEg9HJ"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_json(train_ds_path, encoding=\"utf-8\")\n",
    "val_df = pd.read_json(val_ds_path, encoding=\"utf-8\")\n",
    "test_df = pd.read_json(test_ds_path, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing out some information about the datasets\n",
    "print(f\"Train dataset has {len(train_df)} examples, and the following columns:\")\n",
    "print(train_df.columns.tolist())\n",
    "print()\n",
    "print(f\"Validation dataset has {len(val_df)} examples, and the following columns:\")\n",
    "print(val_df.columns.tolist())\n",
    "print()\n",
    "print(f\"Test dataset has {len(test_df)} examples, and the following columns:\")\n",
    "print(test_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E2bEuKvxostL"
   },
   "outputs": [],
   "source": [
    "# Merge train and validation into one dict with keys `train` and `val`.\n",
    "# This is for training and development, test set has no targets provided.\n",
    "train_val_dict = {\n",
    "    \"train\": train_df.to_dict(\"records\"),\n",
    "    \"val\": val_df.to_dict(\"records\"),\n",
    "}\n",
    "# Convert to HF dataset\n",
    "train_ds = Dataset.from_pandas(train_df, split=\"train\")\n",
    "val_ds = Dataset.from_pandas(val_df, split=\"validation\")\n",
    "test_ds = Dataset.from_pandas(test_df, split=\"test\")\n",
    "dataset = DatasetDict({\"train\": train_ds, \"val\": val_ds})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next steps, we prepare the data for modeling. \n",
    "\n",
    "The features we care about from the dataset are the `gloss` and `examples`, and the target is either `electra`, `bertseg` or `bertmsa`. This means we will train 3 different models on each target.\n",
    "\n",
    "In the preprocessing step, we will tokenize the data and convert it to a format that can be fed into the model. This includes merging the `gloss` and `examples` into a single string, tokenizing the string, and converting the tokens to token ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "025a894f9a9f491c9201b5013281dab3",
      "e0c5fa5af5664619bf8fbfd8664f26f9",
      "c095840625a34054951bb85343e0db1c",
      "ec800c5a1af3419e9722a83bbaac666a",
      "91034c80d54e4b6793c4f724c4081357",
      "79193323fae442beb49fd212942a9f0b",
      "842aab2dbeef4b0495e934284424869a",
      "74dc62946ad74de3b6fbf3fb60b5f6e7",
      "02e1b124b01b45d6ace8bf839e7a96f7",
      "760405edf3bd404698e872fe576a399e",
      "83607b095cce4385a29989a7040abdc9",
      "fce9aa8d3efb4eec8decbc2fa35f2e52",
      "0881a373adab4b2db3a8ee32266850ec",
      "42d22011e34148e0912814d28cca5154",
      "3c0c41bfa2be49e499fa3a23cec67972",
      "2e20c688514241f6b66041f65248da7d",
      "a3791a07a1b74580bb8f24d0c665a71a",
      "42568acc3d7249c3a0ada2f99bf5f362",
      "6122e5e55ade49cb998a50c699db8813",
      "98f3eacfc5464c3d99b2f78d8ae5a93a",
      "e5cabfe735d1450fb900fa5c4e37a26f",
      "c0f84d1b2e5c4f679e48f989a4944c16"
     ]
    },
    "id": "3r_FiV7KostM",
    "outputId": "d544c7f9-1455-4bfa-aa89-c81448d67d2e"
   },
   "outputs": [],
   "source": [
    "# Tokenization step\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, legacy=False)\n",
    "\n",
    "padding = \"max_length\"\n",
    "max_input_length = 256\n",
    "\n",
    "\n",
    "def preprocess_function(items):\n",
    "    # The inputs are the glosses + examples\n",
    "    if \"examples\" in items:\n",
    "        glosses = [\n",
    "            f\"{gloss}. {example[0]}، {example[1]}\"\n",
    "            for gloss, example in zip(items[\"gloss\"], items[\"examples\"])\n",
    "        ]\n",
    "    else:\n",
    "        glosses = items[\"gloss\"]\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        glosses,\n",
    "        max_length=max_input_length,\n",
    "        padding=padding,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    # Adding the 3 types of target embeddings, if they are available.\n",
    "    if \"electra\" in items:\n",
    "        model_inputs[\"electra\"] = items[\"electra\"]  # Electra embeddings\n",
    "    if \"bertseg\" in items:\n",
    "        model_inputs[\"bertseg\"] = items[\"bertseg\"]  # BERTseg embeddings\n",
    "    if \"bertmsa\" in items:\n",
    "        model_inputs[\"bertmsa\"] = items[\"bertmsa\"]  # BERTmsa embeddings\n",
    "\n",
    "    targets = [ex for ex in items[\"word\"]]\n",
    "    # encode the words\n",
    "    labels = tokenizer(\n",
    "        targets,\n",
    "        max_length=max_length,\n",
    "        padding=padding,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).input_ids\n",
    "\n",
    "    # important: we need to replace the index of the padding tokens by -100\n",
    "    # such that they are not taken into account by the CrossEntropyLoss\n",
    "    labels_with_ignore_index = []\n",
    "    for labels_example in labels:\n",
    "        labels_example = [label if label != 0 else -100 for label in labels_example]\n",
    "        labels_with_ignore_index.append(labels_example)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels_with_ignore_index\n",
    "\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "# Final mapping of the dataset\n",
    "dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, data splits are converted into PyTorch `DataLoader` objects for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vtIrY-3Ng-nB"
   },
   "outputs": [],
   "source": [
    "dataset.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"labels\", \"electra\", \"bertseg\", \"bertmsa\"],\n",
    "    output_all_columns=False,\n",
    ")\n",
    "train_dataloader = DataLoader(dataset[\"train\"], shuffle=True, batch_size=8)\n",
    "valid_dataloader = DataLoader(dataset[\"val\"], batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gGjAs0ZFostM",
    "outputId": "de0bfdb2-b5cb-4e85-cbd0-4e5c33445618"
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Electra embeddings shape: 1, {dataset['train']['electra'].shape[1]}\\n\"\n",
    "    f\"BERTseg embeddings shape: 1, {dataset['train']['bertseg'].shape[1]}\\n\"\n",
    "    f\"BERTmsa embeddings shape: 1, {dataset['train']['bertmsa'].shape[1]}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XmuxWaOTostM"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training pipeline is prepared to accept 3 types of targets: `electra`, `bertseg`, and `bertmsa`. The training process is the same for all targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FVdI5YLNostM"
   },
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "mse_loss = nn.MSELoss()\n",
    "\n",
    "\n",
    "def train(\n",
    "    dataloader,\n",
    "    optimizer_,\n",
    "    scheduler_,\n",
    "    device_,\n",
    "    target: TargetEmbeddingType = \"electra\",\n",
    "    validate=False,\n",
    "):\n",
    "    # Use global variable for model.\n",
    "    global model\n",
    "    # Tracking variables.\n",
    "    predictions = []\n",
    "    ground_truth = []\n",
    "    # Total loss for this epoch.\n",
    "    total_loss = 0\n",
    "    if not validate:\n",
    "        model.train()\n",
    "    if validate:\n",
    "        model.eval()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for batch in tqdm(dataloader):\n",
    "        ground_truth += batch[target].numpy().tolist()\n",
    "        inputs = {\n",
    "            k: v.to(device_)\n",
    "            for k, v in batch.items()\n",
    "            if k in [\"input_ids\", \"attention_mask\"]\n",
    "        }\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        if not validate:\n",
    "            model.zero_grad()\n",
    "        embeddings = model(**inputs, labels=labels, return_dict=True)\n",
    "        # Loss is calculated on target embeddings, outside the model.\n",
    "        loss = mse_loss(embeddings, batch[target].to(device_))\n",
    "        total_loss += loss.item()\n",
    "        if not validate:\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer_.step()\n",
    "            scheduler_.step()\n",
    "        predictions += embeddings.tolist()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_epoch_loss = total_loss / len(dataloader)\n",
    "\n",
    "    # Return all true labels and prediction for future evaluations.\n",
    "    return ground_truth, predictions, avg_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aRlFv2-rgz2c"
   },
   "outputs": [],
   "source": [
    "class RevDictModel(nn.Module):\n",
    "    def __init__(self, max_length: int, checkpoint: str):\n",
    "        super().__init__()\n",
    "        model_config = AutoConfig.from_pretrained(checkpoint)\n",
    "        self.base_model = AutoModelForSeq2SeqLM.from_config(model_config)\n",
    "\n",
    "        print(max_length)\n",
    "\n",
    "        # Redefining the linear layer to match the target embedding size (max_length)\n",
    "        self.linear = nn.Linear(self.base_model.config.hidden_size, max_length)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, **kwargs):\n",
    "        # Only using the encoder part to generate embeddings\n",
    "        outputs = self.base_model.encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=True,\n",
    "        )\n",
    "        pooled_emb = (outputs.last_hidden_state * attention_mask.unsqueeze(2)).sum(\n",
    "            dim=1\n",
    "        ) / attention_mask.sum(dim=1).unsqueeze(1)\n",
    "        embedding = self.linear(pooled_emb)\n",
    "        return embedding\n",
    "\n",
    "    def save(self, file):\n",
    "        torch.save(self, file)\n",
    "\n",
    "    @staticmethod\n",
    "    def load(file):\n",
    "        return torch.load(file, map_location=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training per target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters.\n",
    "epochs = 5\n",
    "lr = 4e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y0fFqQh4hGxq"
   },
   "outputs": [],
   "source": [
    "model = RevDictModel(max_length=max_length, checkpoint=checkpoint)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z2o9ySFKostM"
   },
   "outputs": [],
   "source": [
    "# Total number of training steps is number of batches * number of epochs.\n",
    "# `train_dataloader` contains batched data so `len(train_dataloader)` gives\n",
    "# us the number of batches.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=lr,\n",
    "    eps=1e-8,\n",
    ")\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps,\n",
    ")\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "all_loss = {\"train_loss\": [], \"val_loss\": []}\n",
    "\n",
    "# Loop through each epoch.\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    train_labels, train_predict, train_loss = train(\n",
    "        train_dataloader, optimizer, scheduler, device, target=target_embedding\n",
    "    )\n",
    "    valid_labels, valid_predict, val_loss = train(\n",
    "        valid_dataloader, optimizer, scheduler, device, validate=True\n",
    "    )\n",
    "\n",
    "    # Print loss and accuracy values to see how training evolves.\n",
    "    print(\"  train_loss: %.5f - val_loss: %.5f\" % (train_loss, val_loss))\n",
    "    print()\n",
    "\n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    all_loss[\"train_loss\"].append(train_loss)\n",
    "    all_loss[\"val_loss\"].append(val_loss)\n",
    "\n",
    "# Plot loss curves.\n",
    "# plot_dict(all_loss, use_xlabel=\"Epochs\", use_ylabel=\"Value\", use_linestyles=[\"-\", \"--\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L1eVf-8BhJg1"
   },
   "outputs": [],
   "source": [
    "save_directory = f\"/content/drive/MyDrive/mt5_{target_embedding}_checkpoint_0\"\n",
    "model.save(save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oERYxvwNhNgP"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fuOHMoTAhKma"
   },
   "outputs": [],
   "source": [
    "# re-load the model\n",
    "model = RevDictModel.load(\"../checkpoints/mt5_shared_task_checkpoint_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "8SCw9IfqWuyy",
    "outputId": "2824965c-95f3-4418-d3cc-a39cbf0afc41"
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for sample in tqdm(valid_dataloader):\n",
    "    with torch.no_grad():\n",
    "        inputs = {\n",
    "            k: v.to(device)\n",
    "            for k, v in sample.items()\n",
    "            if k in [\"input_ids\", \"attention_mask\"]\n",
    "        }\n",
    "        outputs = model(**inputs)\n",
    "        predictions += outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "veOhKU9uostN"
   },
   "source": [
    "### P@K with Cosine Similarity\n",
    "\n",
    "Here we use the out embeddings and find the top 3 similar words from the test set then find how many of them match the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0rVY89ArostN"
   },
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "from typing import List\n",
    "\n",
    "\n",
    "# Calculate top n words similar to the output embedding\n",
    "def get_top_n(emb: torch.Tensor, predictions: List[torch.Tensor], k: int = 5):\n",
    "    scores = []\n",
    "    for item in predictions:\n",
    "        # Find the similarity score\n",
    "        score = F.cosine_similarity(emb.to(device), item, dim=0)\n",
    "        # Append to total results\n",
    "        scores.append(score.item())\n",
    "    # get top k\n",
    "    return sorted(scores, reverse=True)[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MuZissSEostN"
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "i = 0\n",
    "for item in valid_dataloader.dataset:\n",
    "    emb = item[\"electra\"]\n",
    "    scores.append(get_top_n(emb, predictions, k=3))\n",
    "    i += 1\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UViuiH7nostN"
   },
   "outputs": [],
   "source": [
    "# Get the average score\n",
    "average_at_k = [sum(x) / len(x) for x in zip(*scores)]\n",
    "average = sum(average_at_k) / len(average_at_k)\n",
    "average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-BBePM7Rxq-"
   },
   "source": [
    "# Use it"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "025a894f9a9f491c9201b5013281dab3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e0c5fa5af5664619bf8fbfd8664f26f9",
       "IPY_MODEL_c095840625a34054951bb85343e0db1c",
       "IPY_MODEL_ec800c5a1af3419e9722a83bbaac666a"
      ],
      "layout": "IPY_MODEL_91034c80d54e4b6793c4f724c4081357"
     }
    },
    "02e1b124b01b45d6ace8bf839e7a96f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0881a373adab4b2db3a8ee32266850ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a3791a07a1b74580bb8f24d0c665a71a",
      "placeholder": "​",
      "style": "IPY_MODEL_42568acc3d7249c3a0ada2f99bf5f362",
      "value": "Map: 100%"
     }
    },
    "2e20c688514241f6b66041f65248da7d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c0c41bfa2be49e499fa3a23cec67972": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e5cabfe735d1450fb900fa5c4e37a26f",
      "placeholder": "​",
      "style": "IPY_MODEL_c0f84d1b2e5c4f679e48f989a4944c16",
      "value": " 3921/3921 [00:21&lt;00:00, 179.58 examples/s]"
     }
    },
    "42568acc3d7249c3a0ada2f99bf5f362": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "42d22011e34148e0912814d28cca5154": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6122e5e55ade49cb998a50c699db8813",
      "max": 3921,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_98f3eacfc5464c3d99b2f78d8ae5a93a",
      "value": 3921
     }
    },
    "6122e5e55ade49cb998a50c699db8813": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74dc62946ad74de3b6fbf3fb60b5f6e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "760405edf3bd404698e872fe576a399e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79193323fae442beb49fd212942a9f0b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83607b095cce4385a29989a7040abdc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "842aab2dbeef4b0495e934284424869a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "91034c80d54e4b6793c4f724c4081357": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "98f3eacfc5464c3d99b2f78d8ae5a93a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a3791a07a1b74580bb8f24d0c665a71a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c095840625a34054951bb85343e0db1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_74dc62946ad74de3b6fbf3fb60b5f6e7",
      "max": 31372,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_02e1b124b01b45d6ace8bf839e7a96f7",
      "value": 31372
     }
    },
    "c0f84d1b2e5c4f679e48f989a4944c16": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e0c5fa5af5664619bf8fbfd8664f26f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_79193323fae442beb49fd212942a9f0b",
      "placeholder": "​",
      "style": "IPY_MODEL_842aab2dbeef4b0495e934284424869a",
      "value": "Map: 100%"
     }
    },
    "e5cabfe735d1450fb900fa5c4e37a26f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec800c5a1af3419e9722a83bbaac666a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_760405edf3bd404698e872fe576a399e",
      "placeholder": "​",
      "style": "IPY_MODEL_83607b095cce4385a29989a7040abdc9",
      "value": " 31372/31372 [03:05&lt;00:00, 170.07 examples/s]"
     }
    },
    "fce9aa8d3efb4eec8decbc2fa35f2e52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0881a373adab4b2db3a8ee32266850ec",
       "IPY_MODEL_42d22011e34148e0912814d28cca5154",
       "IPY_MODEL_3c0c41bfa2be49e499fa3a23cec67972"
      ],
      "layout": "IPY_MODEL_2e20c688514241f6b66041f65248da7d"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
